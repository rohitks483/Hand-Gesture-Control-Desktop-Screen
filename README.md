# Hand-Gesture-Control-Desktop-Screen

A Deep Learning Based System which has been trained to recognize hand gestures/movements to performs task/Programs on Desktop Screen.
Like Controling a Media Player, Change Volume, Switch Taks, Forward or Backward Video or Even Skip!

Technology USED:
1) Deep Learning - CNN Algorithm
2) Numpy
3) Pandas
4) OpenCV
5) KeyBoard Mapping

Gestures Trained :-

1) Swipping 2 fingers Up - Volume Up
2) Slidding 2 fingers Down - Volume Down
3) Swipping Right - Move Foorward
4) Swipping Left - Move Backward
5) Drumming Fingers - Start
6) Waving Hand - Mute
7) Stop Sign - Stop

# SCREENSHOTS/ PROCEDURE :-
MAIN SCREEN:
![Screenshot (10)](https://github.com/rohitks483/Real-Time-Facial-Recognition-Based-Attendance-System/blob/main/ReadMe%20Files/1.png)

Entering ID & Name:
![Screenshot (10)](https://github.com/rohitks483/Real-Time-Facial-Recognition-Based-Attendance-System/blob/main/ReadMe%20Files/2.png)

Tap on Click Button To Capture your Image:
![Screenshot (11)](https://github.com/rohitks483/Real-Time-Facial-Recognition-Based-Attendance-System/blob/main/ReadMe%20Files/3.png)

Click on Train Button to Train the Model:
![Screenshot (12)](https://github.com/rohitks483/Real-Time-Facial-Recognition-Based-Attendance-System/blob/main/ReadMe%20Files/4.png)

Click on Track Button to See the Model in Action:
![Screenshot (13)](https://github.com/rohitks483/Real-Time-Facial-Recognition-Based-Attendance-System/blob/main/ReadMe%20Files/5.png)

Press "Q" Button on Keyboard to Exit the Tracking Window

Click on Quit Button to Exit the Application:
![Screenshot (11)](https://github.com/rohitks483/Real-Time-Facial-Recognition-Based-Attendance-System/blob/main/ReadMe%20Files/6.png)
